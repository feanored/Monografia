%!TeX root=../tese.tex
%(dica para o editor de texto: este arquivo é parte de um documento maior)
% para saber mais: https://tex.stackexchange.com/q/78101/183146

\chapter{Perceptron multi-camadas}
\label{cap:perceptron}

Neste capítulo é descrita a implementação e funcionamento de uma versão do algoritmo \eng{perceptron}, feita a partir de um núcleo básico disponibilizado no livro de Kopec \citep{classic}, e a partir do qual modificações e criados novos métodos de treinamento, validação e avaliação do treinamento.

O \eng{perceptron} aqui implementado tem o objetivo de ser utilizado muito mais para fins didáticos do que práticos. Poderá ser usado para tarefas de aprendizagem contanto que sejam problemas que envolvam bases de dados de tamanho pequeno ou mediano. Neste capítulo, é apresentado um exemplo de sua utilização para um famoso problema de classificação de números escritos à mão\footnote{A base de dados MNIST, descrita na seção (\ref{secao:mnist}).}.

Na última parte desse capítulo é exibida uma biblioteca de \eng{machine learning} utilizada nas aplicações reais de \eng{deep learning} de redes neurais, mais avançada, com outros recursos que vão além do escopo que esta versão simples do \eng{perceptron} é capaz de lidar. Esta biblioteca será utilizada nas partes práticas deste trabalho em conjunto com o \eng{perceptron} implementado.

\section{Matemática do algoritmo de retropropagação}

Para a aprendizagem supervisionada foi utilizado o algoritmo de retropropagação (\eng{retropropagation}), que consiste na minimização de uma função de custos, a partir do gradiente descendente, ou seja, de derivadas desta função de custos, neste caso o erro quadrático médio (MSE), que é definido para um par de valores, $x$ e $y$, por:

\[
MSE(x, y) = (x - y)^2
\]

De acordo com Kopec \citep{classic}, explicando em linhas mais gerais nesse momento, o \eng{perceptron} consiste de uma rede na qual os dados se propagam em uma só direção, da camada de entrada para a camada de saída, passando pelas camadas ocultas uma a uma, e por isso recebe o nome de rede \eng{feedforward}. 

Por sua vez, o erro que determinamos na camada de saída propaga-se no caminho inverso, sendo distribuídas correções que vão da saída para a entrada, afetando aqueles neurônios que foram mais responsáveis pelo erro total. Daí vem o nome do algoritmo, a \defi{retropropagação} (das correções para a função de erro).

Estendendo as definições já usadas no capítulo anterior, segue a derivação matemática do algoritmo de retropropagação. Como ficará claro mais à frente, podemos derivar as contas para apenas um neurônio por camada sem perda de generalidade. Dessa forma, se temos uma rede com $L$ camadas, o erro quadrático para um neurônio da camada de saída (a camada $L$) será:
\begin{equation}\label{retro:custo}
C_0 = (a^{(L)} - y)^2
\end{equation}
em que $y$ é a saída observada, e $a^{(L)}$ é a saída de um neurônio da camada de saída.

Temos que $C_0$ é uma função de $a^{(L)}$, uma vez que $y$ é um valor fixo conhecido. Por sua vez, temos que de modo geral a saída de um neurônio é uma função do tipo:
\begin{equation}\label{retro:neuron}
a^{(L)} = \sigma(w^{(L)}~a^{(L-1)} + b^{(L)})
\end{equation}
em que $a^{(L-1)}$ é a saída do neurônio da camada anterior, $w^{(L)}$ é o \defi{peso} atribuído a essa saída, que pode ser visto na Figura \ref{fig:neuronio}, e $b^{(L)}$ é o \defi{viés} desse neurônio, análogo ao parâmetro linear de uma reta. Por fim temos a \defi{função de ativação} que denotamos como $\sigma$ que é aplicada à essa equação linear.

Nota-se que internamente à função de ativação, um neurônio se comporta como uma transformação linear dos neurônios da camada anterior. Caso tivéssemos $n$ neurônios na camada anterior à de saída, teríamos então $n$ pesos, denotados com índice $i$ dessa forma: $\{ w_i^{(L)} \}_{i=1}^n$. Cabe assim à função de ativação, dar o comportamento não-linear à rede \eng{perceptron}.

Como o objetivo é minimizar $C_0$, temos que calcular a influência dos pesos e dos vieses nesse custo. Já sabemos que isso será obtido com o gradiente, isto é, as derivadas parciais dessa função em relação a esses parâmetros, já que são exatamente eles que iremos otimizar. 

De forma mais clara, temos que no início do treinamento da rede, atribuímos valores aleatórios aos pesos e aos vieses, e então executamos o \eng{feedforward}, de forma que a rede irá calcular sequencialmente os valores de saída em todas as suas camadas, obtidos a partir dos dados de entrada, que serão fixos, e desses parâmetros inicialmente aleatórios. A partir daí, poderemos otimizar esses parâmetros.

O cálculo dessas derivadas é feito segundo a regra da cadeia, e adicionalmente iremos denotar a transformação linear interna à função de ativação por $z^{(L)} = w^{(L)}~a^{(L-1)} + b^{(L)}$, de forma que $a^{(L)} = \sigma(z^{(L)})$. Assim, ficamos com as derivadas para a camada de saída:

\begin{equation}\label{retro:1}
\frac{\del C_0}{\del w^{(L)}} = \frac{\del z^{(L)}}{\del w^{(L)}} \frac{\del a^{(L)}}{\del z^{(L)}} \frac{\del C_0}{\del a^{(L)}}
\end{equation}

\begin{equation}\label{retro:2}
\frac{\del C_0}{\del b^{(L)}} = \frac{\del z^{(L)}}{\del b^{(L)}} \frac{\del a^{(L)}}{\del z^{(L)}} \frac{\del C_0}{\del a^{(L)}}
\end{equation}

Podemos calcular diretamente cada um dos termos do lado direito das equações \eqref{retro:1} e \eqref{retro:2}:

\begin{equation}\label{retro:4}
\frac{\del C_0}{\del a^{(L)}} = 2(a^{(L)} - y) ~\propto~ (a^{(L)} - y)
\end{equation}

\begin{equation}\label{retro:5}
\frac{\del a^{(L)}}{\del z^{(L)}} = \sigma^{'}(z^{(L)})
\end{equation}

\begin{equation}\label{retro:6}
\frac{\del z^{(L)}}{\del w^{(L)}} = a^{(L-1)}
\end{equation}

\begin{equation}\label{retro:7}
\frac{\del z^{(L)}}{\del b^{(L)}} = 1
\end{equation}

O que resulta, fazendo todas as substituições, em:

\begin{equation}\label{retro:10}
\frac{\del C_0}{\del w^{(L)}} ~\propto~ a^{(L-1)}~ \sigma^{'}(z^{(L)})~ (a^{(L)} - y)
\end{equation}

\begin{equation}\label{retro:11}
\frac{\del C_0}{\del b^{(L)}} ~\propto~ \sigma^{'}(z^{(L)})~ (a^{(L)} - y)
\end{equation}

Na equação \eqref{retro:4} suprimimos o termo constante ``$2$'', o que propaga a relação de proporção para as equações \eqref{retro:10} e \eqref{retro:11}. Essa proporcionalidade tornar-se-á implícita na implementação do algoritmo com a utilização do fator $\eta$, a \defi{taxa de aprendizagem}. A sua motivação e utilização são explicadas em detalhes no Apêndice \ref{ap:gradiente}. 

O que é importante dizer nesse ponto é que temos expressões conhecidas para calcular as derivadas da função de custo na camada de saída, que serão multiplicadas por $\eta$, que em geral pertence ao intervalo $(0,1)$, por razões computacionais. Analogamente, podemos pensar numa forma de obter expressões para as derivadas do custo das camadas ocultas. A princípio, podemos calcular:

\begin{equation}\label{retro:3}
\frac{\del C_0}{\del a^{(L-1)}} = \frac{\del z^{(L)}}{\del a^{(L-1)}} \frac{\del a^{(L)}}{\del z^{(L)}} \frac{\del C_0}{\del a^{(L)}} \; ,
\end{equation}
usando o fato de que:
\begin{equation}\label{retro:8}
\frac{\del z^{(L)}}{\del a^{(L-1)}} = w^{(L)} \; .
\end{equation}

Agora, seja a $i$-ésima camada oculta tal que $1 < i < L$. Se observarmos \eqref{retro:3}, e fizermos $i = L-1$, usando \eqref{retro:8}, ficamos com:

\begin{equation}\label{retro:9}
\frac{\del C_0}{\del a^{(i)}} = w^{(i+1)} \frac{\del a^{(i+1)}}{\del z^{(i+1)}} \frac{\del C_0}{\del a^{(i+1)}} \;.
\end{equation}

Podemos observar que há um mesmo termo duplo que aparece tanto em \eqref{retro:1} e \eqref{retro:2} quanto em \eqref{retro:9}, de forma que apenas o índice da camada é diferente. Podemos generalizá-lo como o termo \emph{delta da camada $i$}:

\begin{equation}\label{retro:12}
\Delta^{(i)} = \dfrac{\del a^{(i)}}{\del z^{(i)}} \dfrac{\del C_0}{\del a^{(i)}} \;.
\end{equation}

Simplificando todas as demais expressões usando essa definição, ficamos com:

\begin{equation}\label{retro:13}
\frac{\del C_0}{\del w^{(i)}} = a^{(i-1)} \Delta^{(i)}
\end{equation}
e
\begin{equation}\label{retro:14}
\frac{\del C_0}{\del b^{(i)}} = \Delta^{(i)} \;.
\end{equation}

Como vemos, todas as derivadas que precisamos dependem de $\Delta^{(i)}$, que por sua vez depende do termo $\dfrac{\del C_0}{\del a^{(i)}}$ que será calculado de 2 formas distintas:

\[ \dfrac{\del C_0}{\del a^{(i)}} = w^{(i+1)}~ \Delta^{(i+1)}  \;\;\Rightarrow \]
\begin{equation}\label{retro:15}
\Delta^{(i)} = \sigma^{'}(z^{(i)})~ w^{(i+1)}~ \Delta^{(i+1)}
\end{equation}
para as camadas ocultas, e
\[ \dfrac{\del C_0}{\del a^{(L)}} = (y - a^{(L)}) \;\;\Rightarrow \]
\begin{equation}\label{retro:16}
\Delta^{(L)} = \sigma^{'}(z^{(L)})~ (y - a^{(L)})
\end{equation}
para a camada de saída.

Percebe-se a natureza recursiva do algoritmo, onde o caso base é calculado na camada de saída, e que o cálculo vai propagando-se para as camadas ocultas, em direção à camada de entrada. Assim, a retropropagação é calculada sucessivamente, camada a camada, até a primeira camada oculta, já que não se pode alterar a camada de entrada. Este processo é repetido para cada par entrada e saída observada.

Outro fato útil é que a expressão interna do neurônio é uma transformação linear, assim as contas podem ser facilmente ajustadas para o caso geral em que há $n_i$ neurônios em dada camada $i$ da rede, conforme já explicado, e que será detalhado diretamente nos trechos de código que serão mostrados a seguir, na implementação propriamente dita.

\section{Implementação do algoritmo de retropropagação}

A princípio damos uma representação visual da rede \eng{perceptron}, que pode ser vista na Figura \ref{fig:estrutura_rn}. Cada círculo representa um neurônio, cada coluna vertical de neurônios é uma camada da rede, sendo a camada oculta a que está destacada em roxo. As setas representam as conexões entre as camadas de neurônios, cada neurônio de uma camada está ligado a todos os neurônios da camada anterior, o sentido dessa conexão é da esquerda para a direita, o que indica o processo de \eng{feedforward} da rede.

\begin{figure}[htb]
\centering
\includegraphics[width=6cm]{figuras/estrutura_rn}
\caption{Visão estrutural da rede \eng{perceptron}. A linha tracejada destaca uma das camadas da rede.}
\label{fig:estrutura_rn}
\end{figure}

A implementação do \eng{perceptron} deste trabalho teve como base a implementação feita por Kopec \citep{classic}, a partir da qual foram adicionados outros recursos, como o viés dos neurônios, não presente na implementação de Kopec, que desempenha um papel análogo ao do coeficiente linear de uma reta, e o uso da biblioteca \emph{Numpy} para o uso de seus métodos mais eficientes para lidar com listas de números de ponto flutuante. 

Além dessa base, formada pelas classes \emph{Neuron}, \emph{Layer} e \emph{Network}, que serão mostradas nas seções seguintes, também foi implementada a classe \eng{Perceptron}, explicada mais adiante na seção \ref{secao:perceptron}.

\subsection{O neurônio}

O primeiro passo é implementar a classe \emph{Neuron} para representar cada neurônio. Esta é uma classe de entidade, contendo apenas um construtor e o método \eng{output}, que recebe os valores de entrada para esse neurônio, e calcula a saída com os pesos o viés e a função de ativação usada neste neurônio, de acordo com a equação \eqref{retro:neuron}. O Programa \ref{lst:neuron} abaixo mostra este método, em conjunto com o construtor da classe.

\newpage

\estiloR
\begin{lstlisting}[caption={Trecho da classe Neuron}, label={lst:neuron}, escapeinside={\%}]
class Neuron:
    def __init__(self, weights, bias, learning_rate, ativacao, der_ativacao):
        '''(list[float], float, float, Callable, Callable) -> None'''
        ...

    def output(self, inputs):
        '''(list[float]) -> float'''
        self.output_cache = np.dot(inputs, self.weights) + self.bias
        return self.ativacao(self.output_cache)
\end{lstlisting}


A função \emph{np.dot} da biblioteca \emph{Numpy} é utilizada para calcular o produto escalar entre os valores de entrada e os pesos desse neurônio. O valor da transformação linear é armazenado num atributo de classe antes da aplicação da função de ativação, pois será utilizado mais à frente durante o treinamento da rede.

\subsection{A função de ativação}

A função de ativação possui o papel de ativar ou não a saída de um neurônio, conforme visto no capítulo anterior. A forma com que essa ativação ocorre é definida pela função utilizada. Aqui o termo \emph{ativar} significa que a função irá retornar um valor mais próximo de $1$ enquanto que uma não-ativação retornará um valor mais próximo de $0$. Essa é uma restrição para a função de ativação para a camada de saída, que será sempre da forma:

\[ f: \mathbb{R} \rightarrow [0, 1] \;. \]

No caso do neurônio biológico, quando dizemos que ele ativa/transmite ou não o sinal elétrico que chegou até ele, é como se ele \emph{retornasse} apenas $0$ ou $1$. De fato, poderíamos até usar uma função similar a essa em alguma camada de nossa rede artificial, e este tipo de \emph{função escada} teria a seguinte definição:

\[
f(x) = 
\left\{
\begin{array}{lcr}
1 & \text{se} & x \geq 0 \;;\\
0 & \text{se} & x < 0 \;.
\end{array}
\right.
\]

A utilização dessa função de ativação, conforme nos diz Grus \citep{data}, faria com que um neurônio fizesse simplesmente a distinção entre espaços separados pelo hiperplano de pontos tal que $ <w.x> + b = 0$, ou seja, o hiperplano definido pelos pontos de entrada cuja transformação linear resultasse em zero.

Esta função é claramente não contínua e portanto não diferenciável, e precisamos de uma função de ativação que o seja, uma vez que algumas das equações da otimização que calculamos anteriormente, dependem da expressão de sua derivada. É por essa razão, que passou-se a considerar uma aproximação suave da função escada, como a função \textbf{sigmoide}:

\[
\sigma(x) = \frac{1}{1 + e^{-x}} \;.
\]

Ela retorna valores somente no intervalo $[0, 1]$, igualmente à função escada, sua inspiração. A sua derivada pode ser facilmente calculada, simplificando-se na seguinte expressão:

\[
\sigma^{'}(x) = \sigma(x)(1-\sigma(x)) \;.
\]

Podemos comparar o comportamento dessas funções de ativação no gráfico presente na Figura \ref{fig:ativacao} abaixo. A seguir, encontra-se o Programa \ref{lst:ativacao}, destacando um trecho do script \texttt{util.py} com a implementação da função \eng{sigmoide} e de sua derivada.

\begin{figure}[htb]
\centering
\includegraphics[width=12cm]{figuras/ativacao}
\caption{Comparação entre as funções de ativação do tipo escada e a \eng{sigmoide}.}
\label{fig:ativacao}
\end{figure}


\estiloR
\begin{lstlisting}[caption={Trecho do script util.py}, label={lst:ativacao}, escapeinside={\%}]
def sigmoide(x):
    '''(float) -> float'''
    return 1.0 / (1.0 + np.exp(-x))

def der_sigmoide(x):
    '''(float) -> float'''
    sig = sigmoide(x)
    return sig * (1 - sig)
\end{lstlisting}


Com a popularização das redes neurais, várias outras funções de ativação foram criadas para ativar as camadas ocultas do treinamento, devido aos problemas que podem acontecer ao se utilizar função \eng{sigmoide}. Podemos identificar um desses problemas analisando seu gráfico. Vemos que ela se aproxima de $1$, que é a ativação máxima, rapidamente a partir de $x > 4$, e aproxima-se simetricamente de zero com valores a partir de $x < -4$. 

Como o método do gradiente tenta ajustar os valores dos pesos a partir dos valores de saída e esses ajustes dependem da derivada da função de ativação, temos que levar em conta o comportamento da derivada da função \eng{sigmoide}, o qual podemos observar a partir de seu gráfico na Figura \ref{fig:der_sigm}.

\begin{figure}[htb]
\centering
\includegraphics[width=12cm]{figuras/der_sigm}
\caption{Gráficos da função \eng{sigmoide} e sua derivada.}
\label{fig:der_sigm}
\end{figure}

Por construção, a derivada retorna valores sempre menores do que $1/4$, e além disso aproxima-se de $0$ tão rapidamente quanto a \eng{sigmoide} aproxima-se de $1$. Isso faz com que atualizações baseadas na derivada para valores de erro que já estão muito altos não sejam efetivas para diminuí-los, pois justamente nessa região a derivada está muito próxima de $0$. Essa é a principal desvantagem da função \eng{sigmoide}.

Um problema relacionado a este é que se a regra da cadeia em \eqref{retro:1} e \eqref{retro:2}, com as derivadas da função de ativação dadas em \eqref{retro:5} multiplicadas através das várias camadas, pode resultar em: \textbf{i)} num número muito grande, se todas as derivadas resultarem em valores maiores do que zero; ou: \textbf{ii)} num número muito próximo de zero se todas as derivadas forem menores do que zero. Isto faz com que atualizações dadas pelo gradiente sejam instáveis. Este problema é descrito por Matheus Facure \citep{matheus_2} e denominado ``problema do gradiente explodindo/desvanecendo''(\eng{vanishing gradient problem}).

Assim, conforme nos diz Facure \citep{matheus}, a utilização da função \eng{sigmoide} não é mais recomendada em problemas que envolvam redes neurais maiores, sendo bem comum o problema do gradiente explodindo, já que a derivada é sempre maior do que $0$. Porém, o uso da função \eng{sigmoide} é desejável (ou até mesmo necessário) em casos como: \textbf{i)} modelos probabilísticos de variáveis binárias, \textbf{ii)} modelagem de problemas biológicos onde ela é uma aproximação mais plausível da ativação elétrica-biológica, e \textbf{iii)} alguns modelos de redes com aprendizagem não supervisionada.

A próxima função de ativação é o \emph{tangente hiperbólico} (\textbf{tanh}), que é similar à função \eng{sigmoide} e pode ser escrita em função dela. Ela retorna valores no intervalo $[-1, 1]$ mas sua derivada retorna valores mais próximos de $1$, chegando ao valor máximo de $1$ quando $x = 0$. A sua expressão em termos da função \eng{sigmoide} e a sua derivada são dadas por:

\[ tanh(x)=2\sigma(2x) - 1   \quad \text{e} \quad  tanh'(x)=1 - tanh^2(x) \;. \]

Na Figura \ref{fig:tanh} podemos ver o gráfico da função e de sua derivada, a partir do que podemos notar como a derivada da \emph{tanh} retorna valores maiores do que a derivada da função \eng{sigmoide}.

\begin{figure}[htb]
\centering
\includegraphics[width=12cm]{figuras/tanh}
\caption{Gráficos da função tangente hiperbólico e sua derivada.}
\label{fig:tanh}
\end{figure}

O próximo avanço é conseguido com a função de ativação linear retificada (\defi{RELU}). Essa função é quase a função identidade, exceto que na região negativa do domínio ela é identicamente igual a $0$. Ela não é derivável no ponto $x=0$, mas podemos estender a definição fixando seu valor em $1$ nesse ponto. Sua definição e de sua derivada estendida é dada por:

\[
ReLU(x)=max\{0, x\}   \quad \text{e} \quad  ReLU'(x)=
	\begin{cases}
    	1, & \text{se } x\ge 0 \;;\\
    	0, & \text{c.c.} \;.
	\end{cases}
\]

Podemos ver seus gráficos na Figura \ref{fig:relu}, a seguir. Usar essa função de ativação torna até mesmo a execução do código mais rápida, uma vez que não há cálculos matemáticos a serem feitos, apenas uma função de máximo que é trivial. Além disso, podemos notar que a derivada se mantém com o valor $1$ constante enquanto o neurônio é ativado, sendo essa uma forma de tentar resolver o problema do gradiente explodindo/desvanecendo, além de agilizar o processo de treinamento. 

\begin{figure}[htb]
\centering
\includegraphics[width=12cm]{figuras/relu}
\caption{Gráficos da função \eng{RELU} e sua derivada.}
\label{fig:relu}
\end{figure}

Essa é a razão, conforme explica Facure \citep{matheus}, dessa função ter contribuído para o recente aumento de popularidade das redes neurais. Adicionalmente, Bing Xu \citep{xu_relu} ressalta que outra vantagem das funções do tipo \eng{RELU}, além de resolver o problema do gradiente explodindo/desvanecendo, é a de aumentar a velocidade da convergência do algoritmo de treinamento rumo a um mínimo da função de custos.

Uma desvantagem da função \eng{RELU} é a chance de um neurônio ser desativado permanentemente, já que uma vez que ele zera, a função de ativação e sua derivada são ambas iguais a $0$, de forma que ele nunca mais irá aumentar durante o treinamento, tornando-se um neurônio \emph{morto}. Todavia, assim como no caso da \eng{sigmoide}, há casos em que esse comportamento é desejado, por exemplo, na camada de saída de redes de classificação.

O próximo desenvolvimento foi dado pela função conhecida como \eng{Leaky RELU}. Quase idêntica à \eng{RELU}, exceto que na parte negativa do domínio ao invés de $0$ a função retorna $x/\alpha$, com $\alpha \in (0, \infty)$. Isso corrige imediatamente o problema dos neurônios desativados. A definição da função e de sua derivada, dada por Xu \citep{xu_relu}, é:

\[
LeakyReLU(x, \alpha) = 
\begin{cases}
    	x, & \text{se } x\ge 0 \;;\\
    	x/\alpha, & \text{c.c.} \;,
	\end{cases}
\quad \text{e} \quad  
LeakyReLU'(x, \alpha) =
	\begin{cases}
    	1, & \text{se } x\ge 0 \;;\\
    	1/\alpha, & \text{c.c.} \;.
	\end{cases}
\]

A partir dos resultados dos estudos feitos por Xu \citep{xu_relu}, a função \eng{Leaky RELU}, e suas variações, se mostraram consistentemente melhores do que a \eng{RELU} para bases de dados de pequeno e médio portes. Os melhores resultados, encontrados empiricamente pelos autores, foram obtidos com $\alpha = 5.5$. Este parâmetro é conhecido como \defi{vazamento}, que dá o nome à função. Podemos ver o seu comportamento no gráfico da Figura \ref{fig:l_relu}.

\begin{figure}[htb]
\centering
\includegraphics[width=12cm]{figuras/l_relu}
\caption{Gráficos da função \eng{Leaky RELU} e sua derivada.}
\label{fig:l_relu}
\end{figure}

Por fim, temos a função de unidade linear exponencial \eng{ELU}, proposta por Djork-Arné Clevert \citep{clevert}, que é definida, com $\alpha > 0$, por:

\[
ELU(x, \alpha)=
	\begin{cases}
    	x, & \text{se } x\ge 0\;.\\
    	\alpha(e^x - 1), & \text{c.c.}\;,
	\end{cases}
\quad \text{e} \quad
ELU'(x, \alpha)=
	\begin{cases}
    	1, & \text{se } x\ge 0\;;\\
    	\alpha e^x, & \text{c.c.}\;.
	\end{cases} 
\]

Em seu artigo, Clevert \citep{clevert} utiliza o valor $\alpha = 1$, e com a função \eng{ELU} conseguiu performances melhores, tanto de resultados mais corretos, quanto de velocidade de treinamento, em relação às funções \eng{RELU} e \eng{Leaky RELU} para as mesmas bases de dados avaliadas por XU \citep{xu_relu}, mesmo com o uso da função exponencial em sua definição, o que em teoria deveria diminuir a performance do treinamento. Podemos observar o comportamento dessa função e de sua derivada, com $\alpha = 1$ no gráfico mostrado na Figura \ref{fig:elu}.

\begin{figure}[htb]
\centering
\includegraphics[width=12cm]{figuras/elu}
\caption{Gráficos da função \eng{ELU} e sua derivada.}
\label{fig:elu}
\end{figure}

Testes feitos em condições similares por Facure \citep{matheus}, mostram que essa diferença não é tão significativa em relação à \eng{Leaky RELU}, mas que ambas, \eng{Leaky RELU} e a \eng{ELU} são melhores do que a original \eng{RELU}, o que é consistente com o fato delas resolverem teoricamente as desvantagens. São todas melhores escolhas, para camadas ocultas, do que a função \eng{sigmoide}, em todos os estudos acima citados.

Na prática, podemos testar qual função de ativação irá apresentar melhor performance para o problema que queremos resolver. A abordagem mais comum, conforme descrita por Facure \citep{matheus} é utilizar a função \eng{Leaky RELU} nas camadas ocultas, sendo o modo mais simples de obtermos bons resultados graças ao seu comportamento. Podemos avaliar a utilização das outras funções de acordo com o problema em questão, dado que algumas funções podem se sair melhor em alguns contextos específicos, como utilizar a \eng{RELU} nas camadas de saída, ou a \eng{sigmoide} se queremos simular neurônios biológicos, etc.

\subsection{As camadas}

A classe \emph{Layer} representa uma camada de neurônios. Cada camada conecta-se com a sua camada anterior, com exceção da camada de entrada. A rede \eng{perceptron} possui um sentido único de conexão, que vai da entrada para a saída, passando por cada camada oculta. A classe é constituída de uma lista de objetos da classe \emph{Neuron}, uma referência à camada anterior e uma lista para armazenar as saídas dos seus neurônios.

O construtor de \emph{Layer} é responsável por inicializar seus neurônios. Nessa implementação todos os neurônios de uma camada irão usar a mesma função de ativação ($\sigma$) e a mesma taxa de aprendizagem ($\eta$). Além de receber esses parâmetros, o número de neurônios dessa camada, e a referência da camada anterior, o construtor inicializa os pesos de cada neurônio, lembrando que cada neurônio de uma camada possui a mesma quantidade de pesos do que a quantidade de neurônios da camada anterior, e também inicializa o viés de cada neurônio. 

No Programa \ref{lst:layer_1} está o trecho do construtor que inicializa os pesos dos neurônios. Se a camada que estamos inicializando é a camada de entrada, então não criamos pesos e vieses, pois os valores de entrada serão utilizados diretamente como a saída dessa camada, este é o teste presente na linha 11 do Programa, pois a camada de entrada não possui referência a uma camada anterior já que ela é a primeira camada da rede.

A linha 12 do Programa \ref{lst:layer_1} inicializa os pesos dos neurônios da camada. Para fazer isso é utilizada uma função que está definida no script \texttt{util.py}, que sorteia números aleatórios para esses pesos seguindo uma distribuição normal de média $0$ e desvio-padrão $0.3$ e \emph{truncada} no intervalo $[-1, 1]$, para que nenhum peso esteja fora desse domínio e para que em média esse valor seja $0$. O viés é inicializado com um valor constante, próximo de zero, nesse caso com $0.01$.
\newline
\estiloR
\begin{lstlisting}[caption={Trecho da classe \eng{Layer}}, label={lst:layer_1}, escapeinside={\%}]
class Layer:
    def __init__(self, previous_layer, num_neurons, learning_rate,
                 ativacao=None, der_ativacao=None):
        '''(Layer, int, float, Callable, Callable) -> None
        Construtor da Camada de Neurônios
        '''
        ...
        for i in range(num_neurons):
            pesos = None
            bias = None
            if previous_layer is not None:
                pesos = normal_t.rvs(len(previous_layer.neurons))
                bias = 0.01
            
            neuron = Neuron(pesos, bias, learning_rate, ativacao, der_ativacao)
            self.neurons = np.append(self.neurons, neuron)
\end{lstlisting}

Este procedimento é usado para tentar mitigar dois problemas que podem acontecer, conforme explicado por James Dellinger \citep{layers_1}. Se inicializarmos os pesos com muitos números não tão próximos de $0$, numa rede como muitos neurônios e muitas camadas, esses pesos podem somar-se rapidamente através das camadas, resultando em números com valores absolutos muito grandes na camada de saída o que pode prejudicar o treinamento e aprendizado da rede.

Se pelo contrário, inicializarmos todos os pesos com números muito próximos de $0$, ocorre o problema oposto, os neurônios tem seus valores zerados, tornando-se \emph{neurônios desativados}, que se tornam inúteis para o aprendizado já que serão ignorados durante o restante do treinamento. 

Dellinger \citep{layers_1} discute esses problemas no contexto de redes bem grandes, com mais de $100$ camadas, e exibe sua solução heurística que é utilizar uma distribuição normal (não-truncada) com média $0$ e com desvio-padrão $\sqrt{2/n}$, sendo $n$ o número de neurônios da camada anterior.

Para nossos fins didáticos, foram testados alguns desvios-padrão como $1$, $0.3$ e $0.1$, em um dos exemplos que serão mostrados ainda nesse capítulo, e dentre eles, o valor $0.3$ se saiu melhor sendo o suficiente para não explodir e nem desativar os neurônios da única camada oculta que foi usada na aplicação-exemplo em questão.

O desvio-padrão de $0.3$ auxilia na tarefa de restringir os valores no intervalo $[-1, 1]$, sem que precisemos truncar muitos valores, o que poderia aumentar a massa de probabilidade dos extremos $-1$ e $1$, já que valores mais distantes da média do que $3$ vezes o desvio-padrão são raramente obtidos de uma distribuição normal. 

Após inicializar cada neurônio, o salvamos na lista de neurônios dessa camada, que é um dos atributos de classe discutidos no primeiro parágrafo. A próxima tarefa de uma camada é processar as entradas recebidas e retornar as saídas. Podemos observar esse comportamento no Programa \ref{lst:layer_2}.
\newline
\estiloR
\begin{lstlisting}[caption={Trecho da classe \eng{Layer}}, label={lst:layer_2}, escapeinside={\%}]
def outputs(self, inputs):
        '''(list[float]) -> list[float]
        Armazena em cache as saidas dos neuronios e a retornam
        Se for uma camada de entrada, usa elas diretamente
        '''
        if self.previous_layer is None:
            self.output_cache = inputs
        else:
            self.output_cache = np.array([n.output(inputs) for n in self.neurons])
        return self.output_cache
\end{lstlisting}


A camada de entrada não processa os dados, usando-os diretamente. As demais camadas devem processar cada neurônio, usando seu próprio método de processamento, aplicando a transformação linear e em seguida a função de ativação. O resultado é armazenado numa lista \eng{numpy} que é o atributo de classe \texttt{output$\_$cache}, que armazena as saídas dessa camada para uso posterior; por fim, a lista das saídas da camada é retornada.

A última tarefa da classe \eng{Layer} é calcular os termos $\Delta$ definidos em \eqref{retro:15} e \eqref{retro:16}, que definem respectivamente o cálculo que é feito se estamos calculando as derivadas para as camadas ocultas e o cálculo feito para a camada de saída. As duas versões são exibidas no Programa \ref{lst:layer_3} abaixo.
\newline
\estiloR
\begin{lstlisting}[caption={Trecho da classe \eng{Layer}}, label={lst:layer_3}, escapeinside={\%}]
def calcular_delta_camada_de_saida(self, expected):
        '''(list[float]) -> None'''
        for i, neuron in np.ndenumerate(self.neurons):
            der_cost = expected[i[0]] - self.output_cache[i]
            neuron.delta = neuron.der_ativacao(neuron.output_cache) * der_cost

    def calcular_delta_camada_oculta(self, next_layer):
        '''(Layer) -> None'''
        for i, neuron in np.ndenumerate(self.neurons):
            next_weights = np.array([n.weights[i[0]] for n in next_layer.neurons])
            next_deltas = np.array([n.delta for n in next_layer.neurons])
            der_cost = np.dot(next_weights, next_deltas)
            neuron.delta = neuron.der_ativacao(neuron.output_cache) * der_cost
\end{lstlisting}


Os algoritmos são as traduções quase literais de \eqref{retro:15} e \eqref{retro:16}. Podemos ver a natureza recursiva da regra da cadeia nas 2 linhas finais, onde usamos os deltas calculados da próxima camada para calcular os deltas da camada atual. O caso base é a função que calcula o delta da camada de saída. A lógica que orquestra essa recursão está implementada na próxima classe.

\subsection{A rede}

A classe \eng{Network} representa a rede neural como um todo. Ela armazena uma lista de camadas, ou seja, objetos do tipo \eng{Layer}, a partir dos parâmetros que recebe em seu construtor, que são a estrutura da rede que será criada, que é um vetor de inteiros que representam as quantidades de neurônios para cada camada. Além disso, recebe a taxa de aprendizado que será utilizada em toda a rede, nessa versão, e quais as funções de ativação que serão utilizadas nas camadas ocultas e na camada de saída.

O Programa \ref{lst:network_1} exibe o trecho do construtor que cria cada camada e insere na lista de camadas do objeto da classe atual. A camada de entrada não possui camada anterior, nem função de ativação. Além disso, a camada de saída pode utilizar uma função de ativação diferente daquela utilizada pelas camadas ocultas, que usarão a mesma.
\newline
\estiloR
\begin{lstlisting}[caption={Trecho da classe \eng{Network}}, label={lst:network_1}, escapeinside={\%}]
class Network:
    def __init__(self, layer_structure, taxa, ativacoes):
        '''(list[int], float, Tuple[Callable]) -> None'''
        ...
        self.layers = np.array([], dtype=np.float64)
        self.estrutura = layer_structure

        # camada de entrada
        input_layer = Layer(None, self.estrutura[0], taxa)
        self.layers = np.append(self.layers, input_layer)

        # camadas oculta(s)
        for previous, qtd_neurons in np.ndenumerate(self.estrutura[1::l]):
            next_layer = Layer(self.layers[previous[0]], qtd_neurons, taxa,
                               ativacoes[0], ativacoes[1])
            self.layers = np.append(self.layers, next_layer)

        # camada de saída
        output_layer = Layer(self.layers[-1], self.estrutura[-1], taxa,
                               ativacoes[2], ativacoes[3])
        self.layers = np.append(self.layers, output_layer)
\end{lstlisting}


A primeira tarefa da classe Network é o de processar entradas, fazendo elas atravessarem a rede, camada a camada, até a camada de saída, e retornar as saídas obtidas. É o processo de \eng{feedforward} explicado no início do capítulo. Sua implementação mesmo para o caso geral de multi-camadas é bem simples, conforme exibido no Programa \ref{lst:network_2} abaixo.
\newpage
\estiloR
\begin{lstlisting}[caption={Trecho da classe \eng{Network}}, label={lst:network_2}, escapeinside={\%}]
def feedforward(self, entrada):
    '''(list[float]) -> list[float]'''
    ...
    saida = self.layers[0].outputs(entrada)
    for i in range(1, len(self.layers)):
        saida = self.layers[i].outputs(saida)
    return saida
\end{lstlisting}


A próxima tarefa é treinar a rede, passando uma lista de entradas e saídas observadas, realizando o procedimento \eng{backpropagation} para atualizar os pesos e vieses dos neurônios de cada camada, tudo isso em sequência, para cada entrada fornecida. É o que está literalmente implementado no Programa \ref{lst:network_3} abaixo.
\newline
\estiloR
\begin{lstlisting}[caption={Trecho da classe \eng{Network}}, label={lst:network_3}, escapeinside={\%}]
def train(self, entradas, saidas_reais):
    '''(list[list[floats]], list[list[floats]]) -> None'''
    ...
    for i, xs in enumerate(entradas):
        ys = saidas_reais[i]
        _ = self.feedforward(xs)
        self.backpropagate(ys)
        self.update_weights()
        self.update_bias()
	return saida
\end{lstlisting}


Cada chamada à função \eng{train} significa que o procedimento de treinamento sendo executado uma única vez. Cada vez que a rede é treinada dizemos que ela avançou em uma \defi{época} de treinamento. O treinamento consiste em primeiramente executar o \eng{feedforward} para uma entrada, para que as camadas possam armazenar as saídas correspondentes aos valores atuais de seus parâmetros, os pesos e os vieses, assim como as saídas em seus atributos \eng{output$\_$cache}, que serão usados pelo método \eng{backpropagation} a seguir, de acordo com as equações que derivamos para o processo de treinamento.

O funcionamento do método \eng{backpropagation} pode ser visto no Programa \ref{lst:network_4} a seguir. Tudo o que ele faz aqui é calcular os deltas das camadas, na ordem correta, começando pela camada de saída, e depois percorrendo as demais camadas do final para o início da rede, fazendo a chamada para cada objeto da classe \eng{Layer} que constitui a rede.
\newline
\estiloR
\begin{lstlisting}[caption={Trecho da classe \eng{Network}}, label={lst:network_4}, escapeinside={\%}]
def backpropagate(self, saidas_reais):
    '''(list[float]) -> None'''
    # calcula deltas da camada de saída
    last_layer = len(self.layers) - 1
    self.layers[last_layer].calcular_delta_camada_de_saida(saidas_reais)
    # calcula deltas das camadas ocultas
    for l in range(last_layer - 1, 0, -1):
        self.layers[l].calcular_delta_camada_oculta(self.layers[l + 1])
\end{lstlisting}


A seguir, atualiza-se os pesos e os vieses com os métodos correspondentes, que podem ser visualizados no Programa \ref{lst:network_5}. Como os valores são todos armazenados nos atributos de estado dos neurônios e das camadas, implementamos diretamente as contas das equações que obtemos para o método do gradiente e da regra da cadeia da retropropagação. Dessa forma, o que fazemos na classe \eng{Network} é basicamente traduzir a matemática para a sintaxe da linguagem Python.
\newline
\estiloR
\begin{lstlisting}[caption={Trecho da classe \eng{Network}}, label={lst:network_5}, escapeinside={\%}]
def update_weights(self):
    '''(None) -> None'''
    ...
    for layer in self.layers[1:]: # pula a camada de entrada
        for neuron in layer.neurons:
            for w in range(len(neuron.weights)):
                neuron.weights[w,] = neuron.weights[w,] + (neuron.learning_rate
                     * (layer.previous_layer.output_cache[w]) * neuron.delta)

def update_bias(self):
    '''(None) -> None'''
    ...
    for layer in self.layers[1:]: # pula a camada de entrada
        for neuron in layer.neurons:
            neuron.bias = neuron.bias + neuron.learning_rate * neuron.delta
\end{lstlisting}


A próxima tarefa da classe \eng{Network}, uma vez que já foi treinada, é fazer a previsão de classes de novos dados de entrada. Isto é feito pelo método mostrado no Programa \ref{lst:network_6}. Isto significa simplesmente processar as entradas fornecidas pelo método \eng{feedforward}, que usará os parâmetros que foram ajustados anteriormente para fazer os cálculos. 
\newline
\estiloR
\begin{lstlisting}[caption={Trecho da classe \eng{Network}}, label={lst:network_6}, escapeinside={\%}]
def predict(self, entradas, interpretar):
    '''(list[list[floats]], Callable) -> list[list[floats]]
    '''
    self.previsoes = np.array([], dtype=np.float64)
    for entrada in entradas:
        self.previsoes = np.append(self.previsoes, interpretar(self.feedforward(entrada)))
    return self.previsoes.reshape(-1, 1)
\end{lstlisting}


Ao final, os dados da última camada são uma lista, isto é, um vetor de valores reais, que são interpretados por uma função que é passada por parâmetro que identifica a qual classe, previamente definida, pertence esse vetor de saída. A lógica dessa interpretação é externa à classe \eng{Network} e será vista mais adiante. A lista de classes preditas em formato \eng{numpy} é retornada.

A última função dessa classe é calcular uma métrica de avaliação para esta rede, que irá servir de avaliação do quão boa a rede é para classificar os dados utilizados. A métrica mais simples a ser utilizada é a \defi{acurácia} da previsão. Ela basicamente mede a proporção de classificações corretas dentre todas as classificações realizadas para um conjunto de dados. Essa lógica bem simples é implementada no Programa \ref{lst:network_7} abaixo. 
\newline
\estiloR
\begin{lstlisting}[caption={Trecho da classe \eng{Network}}, label={lst:network_7}, escapeinside={\%}]
def validate(self, esperados):
    '''(list[list[floats]], list[list[floats]], Callable) -> float'''
    ...
    corretos = 0
    for y_pred, esperado in zip(self.previsoes, esperados):
        if y_pred == esperado:
            corretos += 1
    acuracia = corretos / len(self.previsoes)
    return acuracia
\end{lstlisting}


Nota-se que ela utiliza as previsões salvas no atributo de classe que é atualizado toda vez que executamos o método \eng{predict}, acima. As classes conhecidas são passadas como parâmetro, uma vez que estamos lidando no \eng{perceptron} com uma aprendizagem supervisionada. Dessa forma, ao treinarmos a rede utilizamos um conjunto de dados para os quais já sabemos as classes, e ainda dividimos esse conjunto em duas partes, as quais chamamos de \defi{conjunto de treino} e de \defi{conjunto de teste ou validação}.

Treinamos a rede com o conjunto de treino, que deve sempre ser a maior parte de nossa partição, uma vez que é a partir dele que iremos usar o \eng{backpropagation} para aproximar as saídas da rede às saídas observadas contidas no conjunto. Géron \citep{hands} cita que tipicamente escolhemos aleatoriamente $20\%$ dos dados como nosso conjunto de teste, ficando o restante como o conjunto de treino. A seguir, podemos calcular a acurácia da classificação do conjunto de treino, e a seguir prever e medir a acurácia do conjunto de teste para comparar os resultados. 

Naturalmente a acurácia para o conjunto de teste tende a ser menor, mas não pode ser muito menor, senão dizemos que nossa rede sofre de um problema de classificação conhecido como \defi{overfitting}, ou sobreajuste, o que significa que ela está boa para lidar com o conjunto com o qual foi treinado, o que era esperado dado que foi construída para isso, mas sofre para classificar dados novos, com os quais não foi treinada, e não é isso o que queremos. 

O que queremos é justamente o contrário, que nossa rede, ou seja, nosso algoritmo de aprendizagem seja bom em \defi{generalizar} os dados de entrada que fornecemos a ele. Anas Al-Masri \citep{network_1} define o termo generalização como a habilidade do modelo para fornecer saídas sensíveis para conjuntos de entradas que ele nunca viu antes. Uma tentativa para melhorar a generalização/prevenir o \eng{overfitting} é a inicialização dos pesos dos neurônios segundo uma distribuição normal de média zero, procedimento explicado anteriormente e que foi implementado na classe \eng{Layer}.

De modo geral, define-se como uma técnica de \defi{regularização} qualquer uma que seja utilizada para reduzir o erro do conjunto de teste às custas do aumento do erro do conjunto de treino. Um exemplo, explicado em detalhes por Yash Upadhyay \citep{yash}, é a adição de termos de penalização (\eng{Parameter Norm Penalties}), à função de custo. Estes termos são expressões que envolvem os pesos e multiplicadas por hiperparâmetros que podem ser ajustados empiricamente dando maior ou menor peso à regularização. Esta função pode ser definida de formas diferentes, sendo as mais comuns as regularizações $L1$ e $L2$.

Um outro exemplo de técnica é o \defi{dropout}, descrita por Amar Budhiraja \citep{network_2}, que consiste em ignorar aleatoriamente alguns neurônios durante o treinamento da rede, isto é, não calculamos deltas durante uma execução do \eng{backpropagation} e nem usamos seu valor em consideração quando processamos uma entrada na rede com o \eng{feedforward}. É como se alguns neurônios fossem ``desativados'' durante a fase de treinamento, o que irá prevenir que os neurônios se tornem dependentes uns dos outros em suas contribuições para diminuir o erro total da rede, de acordo com a interpretação do autor, e dessa forma esse procedimento irá diminuir o sobreajuste aos dados de treino.

Em nosso \eng{perceptron} didático optamos por não implementar nem o \eng{dropout} tampouco as regularizações, já que o objetivo dessa versão aqui demonstrada não é fornecer um modelo que seja utilizado em problemas reais, mas apenas didáticos. Em contrapartida essas técnicas estão presentes e podem ser utilizadas nas bibliotecas de redes neurais que usaremos na parte prática do trabalho.

\subsection{A classe \eng{Perceptron}}
\label{secao:perceptron}

A última classe implementada, não foi baseada em um exemplo, mas criada a partir da necessidade de simplificar a criação da rede, para facilitar os testes do seu funcionamento que iremos realizar. Já discutimos sobre as diferentes taxas de aprendizagem para o gradiente descendente, discutimos sobre as diferentes funções de ativação que podem ser utilizadas nas redes neurais, assim como a sua topologia no que se refere apenas à quantidade de neurônios e a quantidade de camadas de neurônios.

Esses são basicamente os atributos que teremos que ajustar de acordo com a necessidade que os dados utilizados em nosso aprendizado irão criar. Dessa forma criamos a classe \eng{Perceptron} que possui um construtor que irá lidar com a seleção dessas opções. Por enquanto, está no Programa \ref{lst:percep_1} apenas a definição de seu construtor e a documentação explicativa.
\newline
\estiloR
\begin{lstlisting}[caption={Trecho da classe \eng{Perceptron}}, label={lst:percep_1}, escapeinside={\%}]
class Perceptron():
    def __init__(self, N=[1], M=50, ativacao="l_relu", taxa=0.001, debug=0):
	    '''(None, str, list[int], int, float, float, str, float) -> None
	    Construtor da minha classe Perceptron
	    Parâmetros da classe:
	    	*N: quantidade de neurônios da camada oculta, podendo ser especificada um vetor de várias camadas ocultas ou apenas uma.
	    	*M: quantidade de treinamentos desejada, denominado de número de "épocas" da rede, o valor padrão é 50.
	    	*ativacao: escolha de uma das funções de ativação disponíveis para a(s) camada(s) oculta(s).
	    	*taxa: taxa de aprendizagem, padrão de 0.001.
	    	*debug: flag para exibição de parâmetros durante o treinamento'''
	    ...
\end{lstlisting}

No construtor é feita uma seleção dentre as funções de ativação existentes no script \eng{util.py}, de forma que só precisamos passar um texto com o nome da função, que o construtor irá selecionar a função e sua derivada para posteriormente informá-las à classe \eng{Network}. Deixamos por padrão a escolha da função de ativação \eng{Leaky RELU}, de acordo com a orientação geral dada por Facure \citep{matheus}.

O parâmetro $M$ define a quantidade inicial padrão de \defi{épocas} que serão treinadas. Uma época corresponde a uma passagem do conjunto de treino pelo \eng{feedforward} e a seguir pelo \eng{backpropagation}, ou seja, configura um único ajuste dos parâmetros através de nosso algoritmo de treinamento.

A arquitetura de camadas padrão definida pelo parâmetro $N$ ($N=[1]$) serve para uma validação existente no construtor, para não permitir a passagem de uma quantidade negativa ou nula de camadas ou de neurônios. Se quiséssemos uma arquitetura de $3$ camadas com $4, 5, $ e $6$ neurônios cada, por exemplo, então o parâmetro passado durante a criação de um objeto \eng{Perceptron} deveria ser $N = [4, 5, 6]$.

Outra tarefa do construtor é criar um objeto da classe \eng{OneHotEncoder}\footnote{\url{https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html}} da biblioteca \eng{scikit-learn}\footnote{\url{https://scikit-learn.org/stable/index.html}}. Essa é uma das mais famosas e mais utilizadas bibliotecas da linguagem Python para tarefas de aprendizado de máquina. É a biblioteca utilizada pela maioria dos autores dos livros-textos da área de ciência de dados, como por exemplo Géron \citep{hands} e Grus \citep{data}.

Esse objeto codificador (\eng{encoder}) é salvo como um atributo de classe: \texttt{self.\_enc}, e será utilizado no método de treinamento para criar automaticamente as classes numéricas a partir das classes fornecidas pelos conjuntos de treinamento e validação. Essas classes numéricas representam cada classe no formato de um vetor com todos os componentes zerados exceto um, o que identifica unicamente as classes.

Suponha, por exemplo, que estamos treinando um conjunto de fotos que possuem as classes \emph{cachorro}, \emph{gato} e \emph{rato}. A função codificadora poderá transformar a palavra \emph{cachorro} no vetor $[1, 0, 0]$, \emph{gato} no vetor $[0, 1, 0]$ e \emph{rato} no vetor $[0, 0, 1]$. Dessa forma, estes serão os valores esperados para os $3$ neurônios de saída que nossa rede obrigatoriamente deverá ter (número de classes = número de neurônios de saída). A ordem dessa codificação é irrelevante, sendo gerenciada internamente pela classe \eng{OneHotEncoder}.

A seguir, no método utilizado para treinar a rede, que recebe os dados de entrada e as classes conhecidas correspondentes a cada entrada, o primeiro passo é fazer essa codificação. O primeiro trecho do método \texttt{treinar} está no Programa \ref{lst:percep_2}.

\estiloR
\begin{lstlisting}[caption={Trecho da classe \eng{Perceptron}}, label={lst:percep_2}, escapeinside={\%}]
def treinar(self, x_train, y_train, M=0):
    '''(np.array, np.array, int) -> None
    Processo de treinamento da rede neural
    '''
    # onehotencoder extrai as classes únicas já ordenadas alfabeticamente
    y_encoded = self._enc.fit_transform(y_train)
    classes = self._enc.categories_[0]
\end{lstlisting}


Nessa classe e nos exemplos subsequentes neste trabalho, sempre nomeia-se o conjunto dos dados de treino de \texttt{x\_train} e \texttt{y\_train}, e o conjunto de teste de \texttt{x\_test} e \texttt{y\_test}. A letra $x$ indica que é o conjunto de dados de entrada e $y$ indica as classes conhecidas de classificação. No trecho acima utiliza-se a classe \eng{OneHotEncoder} para transformar quaisquer formatos que as classes forem informadas nos vetores numéricos que serão os valores esperados da saída da rede.

O próximo trecho de código irá se encarregar de criar a estrutura geral da rede, ao final criando um objeto da classe \eng{Network} e salvando-o como um atributo de classe. É o que está presente no Programa \ref{lst:percep_3}. Os dados de entrada são esperados no formato de lista do tipo \eng{numpy}, dessa forma a primeira linha do trecho obtém a quantidade de características (\eng{features}) dos dados de entrada, ou seja, das variáveis explicativas do modelo, através do método \texttt{shape(1)} do tipo \eng{numpy}, essa será a quantidade de neurônios da camada de entrada da rede, um para cada característica.

Usando o exemplo das fotos de animais, os pixels da foto seriam as variáveis explicativas para um modelo de classificação, assumindo que todas as fotos possuem a mesma quantidade de pixels e que cada pixel possui apenas um valor de intensidade de cinza, ou outra cor única qualquer. Se utilizássemos fotos coloridas, com por exemplo, as intensidades de $3$ cores diferentes por pixel, então o número de variáveis explicativas de nosso modelo seria $3n$, sendo $n$ o número de pixels da foto.
\newline
\estiloR
\begin{lstlisting}[caption={Trecho da classe \eng{Perceptron}}, label={lst:percep_3}, escapeinside={\%}]
	neurons_in = x_train.shape[1]

	if self.network is None:
	    neurons_out = len(self.classes)
	    for i in range(len(self.N)):
	        if len(self.N) == 1 and self.N[0] < neurons_out:
	            self.N[0] = min(int(np.ceil(neurons_in*2/3 + neurons_out)), neurons_in)
	    
	    rede = []
	    rede.append(neurons_in)
	    for hidden in self.N:
	        rede.append(hidden)
	    rede.append(neurons_out)
	    
	    ativacoes = (self.ativacao, self.der_ativacao, 
	                 self.ativacao_saida, self.der_ativacao_saida)

	    self.network = Network(np.array(rede), self.taxa, ativacoes)
\end{lstlisting}


A seguir, o método irá criar a estrutura da rede, se essa é a primeira vez que o objeto estiver sendo utilizado para o treinamento, do contrário ele irá realizar outras $M$ épocas de treinamento, a partir dos dados existentes na rede. 

Obtém-se a quantidade de neurônios para a camada de saída a partir da quantidade de classes identificadas. A seguir ele utiliza as quantidades de neurônios para as camadas ocultas se estas foram previamente informadas manualmente durante a criação da classe, ou então, é feito um cálculo, para que seja utilizada uma quantidade apropriada de neurônios para a primeira camada oculta, que pode ser a única camada oculta por padrão.

Essa quantidade apropriada é definida por Jeff Heaton \citep{layers_2} como sendo $2/3$ da quantidade de neurônios de entrada mais a quantidade de neurônios de saída. Esta é uma das `regras de ouro' que ele descobriu empiricamente para garantir o bom funcionamento da rede. Outra boa prática que ele encontrou, mais geral mas que satisfaz a primeira, é que a quantidade de neurônios de uma camada oculta única deve ser tal que seja menor que a quantidade de neurônios de entrada mas maior que a quantidade de neurônios de saída.

Naturalmente o treinamento aceita qualquer quantidade de camadas ocultas e de neurônios em cada camada, apenas não há garantias de que o treinamento irá suceder sem ocorrer o problema do gradiente explodindo/desaparecendo. Mesmo a utilização das regras de Heaton \citep{layers_2} não assegura o sucesso do treinamento, apenas testes com outras quantidades de neurônios e camadas, e com outras funções de ativação e taxas de aprendizado que poderão resultar eventualmente num treinamento bem sucedido, caso essas opções-padrão não sejam suficientes.

Essa é uma dificuldade inerente das redes neurais, ainda mais quando tenta lidar com conjuntos de dados muito grandes e com um grande número de variáveis explicativas. Essa é uma das razões principais para ser preferível a utilização de uma biblioteca já consolidada e com muitos anos de desenvolvimento e ajustes por muitos desenvolvedores e cientistas de dados ao redor do mundo.

O próximo trecho, no Programa \ref{lst:percep_4} é o trecho principal deste método, é o treinamento \eng{backpropagation} feito um número $M$ de épocas. São passados como parâmetros os dados de entrada, e as classes conhecidas já codificadas. Ao final desse treinamento, a rede está salva no atributo de classe \texttt{self.network} com os parâmetros já ajustados e prontos para serem utilizados para validação e previsão de novos dados.
\newline
\estiloR
\begin{lstlisting}[caption={Trecho da classe \eng{Perceptron}}, label={lst:percep_4}, escapeinside={\%}]
    for _ in range(self.M):
        self.network.train(x_train, y_encoded)
\end{lstlisting}

O próximo método realiza a previsão das classes a partir dos dados informados, simplesmente utilizando a função da classe \eng{Network} criada para isso. É o que está no Programa \ref{lst:percep_5}, abaixo. 
\newline
\estiloR
\begin{lstlisting}[caption={Trecho da classe \eng{Perceptron}}, label={lst:percep_5}, escapeinside={\%}]
def prever(self, X, interpretar=None):
    '''(np.array, Callable) -> np.array'''
    ...
    if interpretar is None:
        return self.network.predict(X, self.reinterpretar_saidas)
    return self.network.predict(X, interpretar)
\end{lstlisting}


Por padrão a função que irá interpretar os neurônios de saída, convertendo-os em uma classe, foi criada da forma como será mostrada no Programa \ref{lst:percep_6}, a seguir.
\newline
\estiloR
\begin{lstlisting}[caption={Trecho da classe \eng{Perceptron}}, label={lst:percep_6}, escapeinside={\%}]
def reinterpretar_saidas(self, saidas):
    '''(array) -> np.array
    '''
    maximo = max(saidas)
    saida = np.array([int(x == maximo) for x in saidas])
    return self._enc.inverse_transform(saida.reshape(1, -1))
\end{lstlisting}


Essa função realiza a interpretação padrão dos neurônios de saída, primeiramente eles são convertidos em vetores com identificação única, ou seja, no formato $[0, \ldots,0, 1, 0, \ldots, 0]$, sendo que a posição que irá receber $1$ é aquela que tiver originalmente o valor máximo, ou seja, mais distante de $0$, e o restante será convertido em zeros. Dessa forma, basta utilizarmos a decodificação inversa do objeto \eng{OneHotEncoder}, que está salvo no atributo de classe, e daí obtemos qual a classe mais provável à qual pertence o dado de entrada que foi processado pela rede.

Isto nos mostra que uma possível interpretação dos neurônios de saída é que cada um possui uma probabilidade de que o dado pertença àquela classe indexada na mesma posição a qual esse neurônio está na camada de saída. Se usarmos como exemplo nosso modelo fictício dos animais, ao processar uma foto, a rede iria devolver os valores dos neurônios de saída, por exemplo, como o seguinte vetor: $[0.002, 0.976, 0.013]$. Pode-se dizer que há uma probabilidade maior de que essa foto pertença à segunda classe, que digamos ser a classe \emph{Gatos}, por exemplo.

O que a função \texttt{reinterpretar\_saidas} faz é converter esse vetor de saídas da rede no vetor $[0, 1, 0]$, que agora está no formato das classes numéricas geradas por nosso objeto codificador. Dessa forma, executar uma decodificação com esse mesmo objeto, que havia originalmente codificado a palavra \emph{Gato} no vetor $[0, 1, 0]$, irá fazer a operação inversa, retornando a palavra \emph{Gato} como sendo a classe mais provável para a foto processada.

Alternativamente podemos utilizar outra função de interpretação dos dados de saída, devendo ser informada diretamente por referência para o método \texttt{prever}.

Por razões didáticas, se quisermos observar diretamente os valores calculados pela rede sem interpretação, criamos um método que realiza apenas o \eng{feedforward} para uma lista de entradas fornecidas como parâmetro. É o que vemos no Programa \ref{lst:percep_7}, a seguir.
\newline
\estiloR
\begin{lstlisting}[caption={Trecho da classe \eng{Perceptron}}, label={lst:percep_7}, escapeinside={\%}]
def processar(self, X):
    '''(np.array) -> np.array'''
    ...
    saidas = []
    for x in X:
        saidas.append(self.network.feedforward(x))
    return np.array(saidas)
\end{lstlisting}


Por fim, podemos querer observar qual o erro, ou custo, que nossa rede está produzindo para um dado par de conjuntos de entrada e saídas observadas. Para isso criamos o método \texttt{funcao\_erro} exibido no Programa \ref{lst:percep_8}, a seguir. 
\newline
\estiloR
\begin{lstlisting}[caption={Trecho da classe \eng{Perceptron}}, label={lst:percep_8}, escapeinside={\%}]
def funcao_erro(self, X, Y):
    '''(np.array, np.array) -> float'''
    ...
    y_encoded = self._enc.fit_transform(Y)
    return self.network.mse(X, y_encoded)
\end{lstlisting}


Ele utiliza a função de erro que está implementada na classe \eng{Network}, que é a função de custo que utilizamos como base para a criação de nosso algoritmo de otimização, o erro quadrático médio (MSE), também conhecido como a norma euclidiana do vetor distância entre os vetores das saídas observadas e o das saídas obtidas pela rede.

Em todos os trechos da classe \eng{Perceptron} acima, várias linhas estão ocultas sob o símbolo de reticências, são linhas que fazem verificações dos dados utilizados e do estado atual do objeto, se ele pode ser usado para previsão por exemplo, ou seja, se já foi treinado previamente, entre outras verificações gerais para um bom funcionamento.

\section{Exemplo de utilização do \eng{perceptron}}
\label{secao:mnist}

Para demonstrar a utilização da versão aqui implementada da rede \eng{perceptron}, utilizaremos aquela que é considerada a base de dados de entrada no mundo da ciência de dados, a base MNIST (\eng{Modified National Institute of Standards and Technology}) de números escritos à mão, compilada originalmente pela Universidade de Nova York\footnote{Disponível originalmente em \url{http://yann.lecun.com/exdb/mnist/}.}.

A versão oficial da base de dados consiste de $60$ mil imagens de dimensões $28 \times 28$ pixels. Cada imagem é uma foto de um dígito manuscrito entre $0$ e $9$, sendo que a proporção de cada dígito é aproximadamente de um décimo, além disso a base contém a informação dos valores nominais de cada número, o que torna essa base de dados muito útil para validar modelos de aprendizado supervisionado, antes que sejam utilizados em casos reais. Exemplos de fotos estão na Figura \ref{fig:mnist_fig}.

\begin{figure}[htb]
\centering
\includegraphics[width=8cm]{figuras/mnist}
\caption{Exemplos de fotos da base de dados MNIST de números manuscritos.\footnote{Extraído de \url{https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/02/Plot-of-a-Subset-of-Images-from-the-MNIST-Dataset-1024x768.png}}}
\label{fig:mnist_fig}
\end{figure}

Para nosso teste, o primeiro passo foi obter uma versão mais \emph{leve} da base de dados, com as fotos redimensionadas para $8 \times 8$ pixels, o que implica em $64$ variáveis explicativas e mesmo número de neurônios de entrada. Além disso essa base possui apenas $1.800$ fotos etiquetadas. A base original de $28^2 = 784$ pixels já se mostrou grande demais para essa implementação conseguir lidar em tempo hábil.\footnote{Em tentativas que fiz com a base original, meu computador ficou calculando deltas por quase 2 horas sem completar uma só época de treinamento.}

A base foi importada através da biblioteca \eng{sklearn}, que já possui opções para fazer download automático para o programa em execução de várias versões da base MNIST. O código do Programa \ref{lst:mnist_1} mostra a importação e também o próximo passo, que é separar a base nos conjuntos de treino, com $85\%$ dos dados, e de validação com os $15\%$ restantes.
\newline
\estiloR
\begin{lstlisting}[caption={Trecho do script \eng{mnist\_test.py}}, label={lst:mnist_1}, escapeinside={\%}]
# obtendo o conjunto de imagens de numeros escritos
from sklearn.datasets import load_digits
mnist = load_digits()

# dividindo a base nos conjuntos de treino e de teste
N = int(mnist.data.shape[0]*0.8)
x_train, y_train = mnist.data[:N], mnist.target[:N].astype(np.uint8)
x_test, y_test = mnist.data[N:], mnist.target[N:].astype(np.uint8)
\end{lstlisting}


Dada a arquitetura escolhida durante a implementação, para a tarefa de treinar a classificação dos números digitados, não precisamos de mais de meia dúzia de linhas de código, mostradas no Programa \ref{lst:mnist_2}.
\newline
\estiloR
\begin{lstlisting}[caption={Trecho do script \eng{mnist\_test.py}}, label={lst:mnist_2}, escapeinside={\%}]
perceptron = Perceptron(taxa=0.001, ativacao="elu", N=[48, 24])
perceptron.treinar(x_train, y_train, M=20)

y_train_pred = perceptron.prever(x_train)
score = Scores(y_train, y_train_pred)
score.exibir_grafico("Dados de treino")

y_test_pred = perceptron.prever(x_test)
score = Scores(y_test, y_test_pred)
score.exibir_grafico("Dados de teste")
\end{lstlisting}


Basicamente, uma rede é criada com a estrutura de uma camada de entrada com $64$ neurônios, quantidade obtida automaticamente pela classe a partir das dimensões da lista de dados informada (\eng{y\_train}), duas camadas ocultas com $48$ e $24$ neurônios cada, com taxa de aprendizado $0.001$ e a função de ativação \eng{ELU}, sendo este o conjunto de parâmetros que obteve o melhor desempenho. A segunda linha realiza o treinamento com $20$ épocas, informando a lista de imagens e a lista das classificações conhecidas.

As duas últimas linhas desso Programa fazem a comparação dos valores previstos com os valores já conhecidos da classificação, para conhecermos a acurácia de nosso modelo de aprendizado. Abaixo, nas Figuras \ref{fig:mnist_treino} e \ref{fig:mnist_test}, está uma exibição gráfica com a função de erro MSE, a acurácia e a \defi{matriz de confusão}, a partir da qual podemos calcular a acurácia de nossa rede neural.

A matriz de confusão permite relacionar as classes conhecidas com as classes previstas de um conjunto de dados utilizados num algoritmo de aprendizagem supervisionada como é o caso do \eng{perceptron}. Ela mostra as contagens dessas relações, e dessa forma, a diagonal dessa matriz possui as classificações corretamente obtidas pelo algoritmo, e o restante da matriz a contagem das classificações incorretas.

\begin{figure}[htb]
\centering
\includegraphics[width=9cm]{figuras/mnist_treino}
\caption{Matriz de confusão e acurácia do conjunto de treino da base MNIST ${8\times8}$ pixels.}
\label{fig:mnist_treino}
\end{figure}

\begin{figure}[htb]
\centering
\includegraphics[width=9cm]{figuras/mnist_test}
\caption{Matriz de confusão e acurácia do conjunto de teste da base MNIST ${8\times8}$ pixels.}
\label{fig:mnist_test}
\end{figure}

Como os pesos da rede são inicializados aleatoriamente, cada treinamento pode obter resultados levemente diferentes, embora no geral os resultados irão depender mais dos parâmetros utilizados, como a função de ativação, quantidade de camadas, de neurônios e de épocas de treinamento.

Podemos notar que o conjunto de treino possui uma boa performance, obtendo mais de $93.9\%$ de acurácia, ou seja, de classificações corretas. Por outro lado, o conjunto de teste obteve pouco mais de $83.6\%$, o que indica o problema de \eng{overfitting} em nossa rede, quando a classificação do treino está boa, o que é esperado dado que é a base utilizada para o ajuste dos parâmetros internos, mas quando a rede treinada tenta lidar com dados inéditos, o que é o papel do conjunto de teste, se sai consideravelmente pior.

Podemos melhorar o desempenho do classificador com a utilização de alguma implementação mais robusta, e refinada com anos de contribuições da comunidade de programadores e cientistas de dados ao redor do planeta. E uma delas, é a API Keras, que veremos na próxima seção, e que será utilizada no restante desse trabalho.

\section{Utilizando a API Keras}

De acordo com seu site oficial\footnote{\url{https://keras.io/about/}}, \eng{Keras} é uma API (Interface de Programação de Aplicativos) de \eng{deep learning} escrita em Python, e que roda sobre a plataforma de \emph{deep learning} chamada de \eng{TensorFlow}\footnote{Criada pelo Google e disponível em: \url{https://www.tensorflow.org/}} que é de fato a biblioteca que devemos instalar em nosso ambiente Python, para podermos utilizar as redes neurais ali implementadas e quaisquer outros recursos da API \eng{Keras} em nosso projeto de aprendizado.

\eng{Keras} implementa quase todas as arquiteturas de redes neurais, segundo Géron \citep{hands}, sua popularidade é devido à sua facilidade de uso e flexibilidade aliadas a um design de software bem construído. Existem algumas implementações da API, como a \emph{TensorFlow}, que é a principal, a \eng{Microsoft Cognitive Toolkit}, a \eng{Apache MXNet}, a \eng{Apple's Core ML}, etc. 

Todas essas implementações podem ser utilizadas em conjunto, na biblioteca conhecida como \eng{multibackend Keras}, sendo que a escolha entre as implementações ocorre de forma transparente para o cientista de dados. Alternativamente, utilizar a versão própria presente na biblioteca \eng{TensorFlow} traz benefícios, como alguns recursos exclusivos dela. O funcionamento das duas implementações está na Figura \ref{fig:tensor_flow}, a seguir.

\begin{figure}[htb]
\centering
\includegraphics[width=12cm]{figuras/tensor_flow}
\caption{As duas implementações da API Keras. \eng{Multibackend} à esquerda e \eng{TensorFlow} à direita.\footnote{Extraído de: Aurélien Géron, `Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow', O'Reilly 2.a edição 2019, página 385.}}
\label{fig:tensor_flow}
\end{figure}

Para entender o funcionamento e uso do Keras, criamos uma rede com a mesma estrutura do \eng{perceptron} aqui implementada, mas com algumas melhorias já inerentes à API, com objetivo de classificar o mesmo conjunto de dados MNIST, para comparar a eficiência. O primeiro passo é importar a base de dados, sendo a mesma que usamos anteriormente, então reutilizamos o mesmo trecho de código mostrado no Programa \ref{lst:mnist_1}.

O próximo passo é criar a rede utilizando a API Keras, o que vemos no Programa \ref{lst:keras_1}. A primeira linha cria uma rede sequencial, isto é, uma rede \eng{feedforward}. A seguir, são adicionadas as camadas, a primeira camada é definida como \eng{Flatten} pois é a camada de entrada, então ela não aplica nenhuma transformação nos dados.
\newline
\estiloR
\begin{lstlisting}[caption={Trecho do script \eng{mnist\_keras.py}},label={lst:keras_1},escapeinside={\%}]
model = tf.keras.Sequential()
layers = tf.keras.layers
model.add(layers.Flatten())
model.add(layers.Dense(48, activation='elu'))
model.add(layers.Dense(24, activation='elu'))
model.add(layers.Dense(10, activation='softmax'))
\end{lstlisting}


As próximas camadas são adicionadas com o tipo \eng{Dense}, o que significa uma conexão de todos os neurônios de uma camada com todos da próxima, dessa forma estamos criando um \eng{perceptron} exatamente como aquele implementado. 

As camadas ocultas utilizam a função de ativação \eng{ELU}, e a camada de saída utiliza a função \eng{softmax}, o que na API Keras significa que estamos classificando os dados de acordo com o valor máximo dos neurônios de saída, o que em nossa implementação foi papel da função \texttt{reinterpretar\_saidas}, que foi definida no Programa \ref{lst:percep_6}.
\newpage
\estiloR
\begin{lstlisting}[caption={Trecho do script \eng{mnist\_keras.py}},label={lst:keras_2},escapeinside={\%}]
model.compile(optimizer=keras.optimizers.SGD(lr=0.001),
              loss='sparse_categorical_crossentropy', metrics=['accuracy'])
\end{lstlisting}

No Programa \ref{lst:keras_2}, definimos os parâmetros finais da rede. Define-se a função de otimização\footnote{\url{https://keras.io/api/optimizers/}} \eng{SGD} (\eng{Stocastic Gradient Descent})\footnote{\url{https://keras.io/api/optimizers/sgd/}}, quase idêntica à implementação do gradiente descendente implementada, mas ao invés de utilizar todas as imagens de treino numa época de treinamento, algumas são escolhidas aleatoriamente, e isso é feito um certo número de vezes, e os deltas são escolhidos para o conjunto aleatório que tenha se saído melhor, de acordo com a função de perda e métrica utilizadas.

A função de perda é escolhida com a opção \eng{sparse\_categorical\_crossentropy}, pois é a opção padrão do Keras para tarefas de classificação, não sendo possível utilizar a função MSE como antes, por limitações de projeto da API, o que significa que ela irá tratar as categorias de dados da forma que ela foi obtida, com as $10$ classes de $0$ a $9$, onde cada imagem pertence a apenas uma dessas classes. 

Esse parâmetro seria diferente se fosse criada uma rede para classificação binária, por exemplo, ou então se nossos vetores \texttt{y\_train} e \texttt{y\_test} tivessem sido codificados em vetores do tipo $[0,\ldots,1,0,\ldots]$ da forma que foi feita na nossa implementação.

Por fim a acurácia é escolhida como a métrica para avaliação da rede, e que será utilizada pelo gradiente estocástico para definir o melhor sub-conjunto de treino durante uma dada época de treinamento. Basta treinar a rede como o método \eng{fit}, especificando o número de épocas de treinamento desejado, neste caso $20$ foram suficientes, o que é mostrado no Programa \ref{lst:keras_3}.
\newline
\estiloR
\begin{lstlisting}[caption={Trecho do script \eng{mnist\_keras.py}},label={lst:keras_3},escapeinside={\%}]
model.fit(x_train, y_train, epochs=20)

# avaliando dados de treinamento
model.evaluate(x_train, y_train, verbose=2)
# avaliando os dados de teste
model.evaluate(x_test, y_test, verbose=2)

# prevendo a partir dos dados de teste
y_train_pred = np.argmax(model.predict(x_train), axis=-1)
y_test_pred = np.argmax(model.predict(x_test), axis=-1)

# usando a minha classe de validação que mostra a matriz de confusão
score_test = Scores(y_test, y_test_pred)
score_test.exibir_grafico("Dados de teste")
\end{lstlisting}


Nesse Programa também está a avaliação da rede, para o conjunto de treino e para o conjunto de teste. Os resultados obtidos após $20$ épocas de treinamento foram $99.0\%$ de acurácia para o conjunto de treino e $89.7\%$ para o conjunto de teste. 

Por fim podemos fazer previsões com a rede treinada, nesse caso a API possui o método \eng{predict} que irá retornar os valores da camada de saída, ou seja, as probabilidades de cada imagem pertencer à uma das $10$ classes informadas durante o treinamento.

Nas últimas linhas do Programa \ref{lst:keras_3}, está a lógica de obter a classificação predita para o conjunto de teste; utiliza a função \eng{argmax} para obter a classe que obteve a probabilidade máxima. E por fim exibe a matriz de confusão dessa predição, o que está na Figura \ref{fig:keras_test}.

\begin{figure}[htb]
\centering
\includegraphics[width=9cm]{figuras/keras_test}
\caption{Matriz de confusão, função de perda e acurácia do conjunto de teste da base MNIST ${8\times8}$ pixels, utilizando a API Keras.}
\label{fig:keras_test}
\end{figure}

Vemos que a API produz melhores resultados, levando em conta a mesma base de dados, a mesma arquitetura de rede e o mesmo algoritmo de treinamento. A diferença será possivelmente devida a alguma estratégia interna de implementação, a princípio oculta aos usuários, que faz com que os resultados sejam melhores. 

Mesmo assim, como não utilizamos diretamente outros recursos de melhoria disponíveis, ainda é possível notar o \eng{overfitting}, dado que a acurácia no conjunto de teste permanece menor que a acurácia no conjunto de treino. 

A seguir, testamos com a versão oficial da base de dados, de dimensão maior de pixels (${28\times28}$), o que é possível já que a biblioteca está implementada com muita eficiência e funciona bem para bases maiores mesmo num ambiente pessoal de computação. O código está na íntegra no Programa \ref{lst:keras_4}.
\newpage
\estiloR
\begin{lstlisting}[caption={Trecho do script \eng{mnist\_keras.py}},label={lst:keras_4},escapeinside={\%}]
# obter os dados
mnist = fetch_openml('mnist_784', version=1) # versao 28x28
# definição do modelo
model = tf.keras.Sequential()
layers = tf.keras.layers
model.add(layers.Flatten(input_shape=(28, 28)))
model.add(layers.Dense(512, activation='elu'))
model.add(layers.Dense(256, activation='elu'))
model.add(layers.Dense(128, activation='elu'))
model.add(layers.Dense(10, activation='softmax'))
# gerar o modelo
model.compile(optimizer=keras.optimizers.SGD(lr=0.001),
              loss='sparse_categorical_crossentropy', metrics=['accuracy'])
# treinar e prever
model.fit(x_train, y_train, epochs=15)
model.evaluate(x_train, y_train, verbose=2)
model.evaluate(x_test, y_test, verbose=2)
y_pred = np.argmax(model.predict(x), axis=-1)
# validar e medir desempenho
score = Scores(y_test, y_pred)
score.exibir_grafico("Dados de teste")
\end{lstlisting}


A importação da base é feita agora usando outra função da biblioteca \emph{sklearn}. A seguir, os dados são divididos entre os conjuntos de treino e de teste, com as listas \texttt{x\_train, x\_test} e \texttt{y\_train, y\_test} contendo os pixels e as classificações respectivamente, como antes.

Dessa vez, a rede é criada de acordo com o tamanho da base utilizada, como a camada de entrada é bem maior, já que são ${28\times28 = 784}$ pixels. Criamos $3$ camadas ocultas, com os valores progressivamente menores, mas usando ainda a mesma estrutura densa e com a camada final novamente com $10$ neurônios representando os diferentes algarismos.

Por fim, obtemos da mesma forma que no caso anterior, a classificação predita para o conjunto de teste. Dessa vez os resultados são $99.9\%$ de acurácia no conjunto de treino e $96.4\%$ de acurácia no conjunto de teste, conforme pode ser visto na Figura \ref{fig:keras_test_2}, junto com a matriz de confusão.

\begin{figure}[htb]
\centering
\includegraphics[width=9cm]{figuras/keras_test_2}
\caption{Matriz de confusão, função de perda e acurácia do conjunto de teste da base MNIST ${28\times28}$ pixels, utilizando a API Keras.}
\label{fig:keras_test_2}
\end{figure}

É notável a eficiência da API em comparação à nossa implementação simples. A rede é treinada em menos de $2$ minutos, mesmo sendo utilizada a base MNIST original que possui muito mais pixels e também muito mais imagens, $60$ mil em comparação às $2$ mil da base menor utilizada anteriormente. 

Além disso a acurácia final do conjunto de treino é praticamente perfeita, e a acurácia do conjunto de treino, apesar de muito melhor em relação ao \eng{perceptron} implementado, ainda está relativamente menor do que a acurácia do treino. Isto indica que mesmo na versão \eng{Keras} do \eng{perceptron} existe o problema de \eng{overfitting}, ainda que em menor intensidade.

A estratégia utilizada no contexto de \eng{deep-learning} é sobretudo de tentativa e erro, e conforme um cientista de dados vai fazendo isso muitas vezes vai construindo conhecimentos sobre qual arquitetura usar para um problema e qual otimização funciona melhor, uma vez que isso irá sempre variar de acordo com a base de dados utilizada, seja para classificação seja para regressão.

Uma tentativa recente de melhora nessa estratégia foi a criação de uma biblioteca cujo objetivo é o de justamente testar entre diversas arquiteturas e demais parâmetros de criação de uma rede neural, qual a que se sairá melhor para um dado conjunto de dados e objetivo de aprendizagem. Essa biblioteca é chamada de \eng{AutoKeras} e pertence à essa nova vertente de \eng{deep-learning} conhecida como AutoML (\eng{Automated Machine Learning}).

Os objetivos da AutoML, segundo Andre Ye \citep{automl}, são tornar o \eng{deep-learning} mais acessível para o aprendizado de todos os entusiastas, e acelerar o desenvolvimento de pesquisas nessa área, para tornar a criação de conhecimentos mais sólidos e gerar mais compreensão e interpretabilidade para modelos de redes neurais.

Em seu artigo, Andre Ye \citep{automl} demostra como instalar e utilizar o \eng{AutoKeras}. Resumidamente, o que fazemos é fornecer uma base de dados, e ela irá fazer todo o trabalho de escolha da arquitetura e a otimização dos parâmetros, e ao final retornará um objeto da API Keras, que poderá ser usado tanto para tarefas de classificação quanto de regressão. Uma desvantagem a ser considerada é o tempo de processamento da biblioteca \eng{AutoKeras}, que pode ser longo, dado a quantidade de arquiteturas disponíveis e o conjunto de parâmetros de cada uma. 

Dessa forma, para problemas de menor escala, tanto de quantidade de dados utilizada quanto de poder computacional disponível, o que inclui o que iremos fazer a seguir na previsão de séries temporais, é mais viável testar dentre alguns poucos parâmetros previamente escolhidos a partir da experiência de outros cientistas de dados, o que implica num tempo consideravelmente menor de processamento.
