% Exemplos de vários tipos de referências
% https://verbosus.com/bibtex-style-examples.html

@Book{hands,
 author   = {Aurélien Géron},
 title    = {Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow},
 edition  = {2º},
 publisher= {O'Reilly},
 year     = {2019},
}

@Book{classic,
 author   = {David Kopec},
 title    = {Problemas Clássicos de Ciência da Computação com Python},
 edition  = {1º},
 publisher= {Novatec},
 year     = {2019},
}

@Book{data,
 author   = {Joel Grus},
 title    = {Data Science do Zero},
 edition  = {1º},
 publisher= {O'Reilly},
 year     = {2016},
}

@Book{apostila,
author = {Pedro A. Morettin and Julio M. Singer},
title = {Introdução à Ciência de Dados - Fundamentos e Aplicações},
publisher = {Departamento de Estatística. Universidade de São Paulo},
year = {2020},
}

@phdthesis{doutorado,
  author = {Rosangela Ballini},
  title = {Análise e Previsão de Vazões Utilizando Modelos de Séries Temporais, Redes Neurais e Redes Neurais Nebulosas},
  school = {Faculdade de Engenharia Elétrica e de Computação da Universidade Estadual de Campinas},
  year = {2000},
  type = {Doutorado em Engenharia Elétrica}
}

@Book{carroll,
 author   = {Bradley W. Carroll and Dale A. Ostlie},
 title    = {An Introduction to Modern Astrophysics},
 edition  = {2º},
 publisher= {Addison Wewley Longman},
 year     = {2006},
}

@article{blei,
  author  = {David M. Blei and Padhraic Smyth}, 
  title   = {Science and data science},
  journal = {PNAS},
  year    = 2017,
  number  = 33,
  pages   = {8689–8692},
  month   = 8,
  volume  = 114
} 

@MISC{wiki,
  title = {Ciência de Dados},
  howpublished = {\url{https://pt.wikipedia.org/wiki/Ci\%C3\%AAncia_de_dados}},
  month  = {3},
  year = {2020}
}

@article{fuzzy_1,
title = "Fuzzy sets",
journal = "Information and Control",
volume = "8",
number = "3",
pages = "338 - 353",
year = "1965",
issn = "0019-9958",
doi = "https://doi.org/10.1016/S0019-9958(65)90241-X",
url = "http://www.sciencedirect.com/science/article/pii/S001999586590241X",
author = "Lotfi Aliasker {Zadeh}",
abstract = "A fuzzy set is a class of objects with a continuum of grades of membership. Such a set is characterized by a membership (characteristic) function which assigns to each object a grade of membership ranging between zero and one. The notions of inclusion, union, intersection, complement, relation, convexity, etc., are extended to such sets, and various properties of these notions in the context of fuzzy sets are established. In particular, a separation theorem for convex fuzzy sets is proved without requiring that the fuzzy sets be disjoint."
}

@article{fuzzy_2, 
  author={Li-Xin {Wang}}, journal={[1992 Proceedings] IEEE International Conference on Fuzzy Systems}, title={Fuzzy systems are universal approximators}, 
  year={1992}, month={03}, volume={}, number={}, pages={1163-1170}, 
  abstract={The author proves that fuzzy systems are universal approximators. The Stone-Weierstrass theorem is used to prove that fuzzy systems with product inference, centroid defuzzification, and a Gaussian membership function are capable of approximating any real continuous function on a compact set to arbitrary accuracy. This result can be viewed as an existence theorem of an optimal fuzzy system for a wide variety of problems.<>}, 
  keywords={fuzzy set theory;inference mechanisms;modelling;universal approximators;Stone-Weierstrass theorem;product inference;centroid defuzzification;Gaussian membership function;real continuous function;compact set;optimal fuzzy system;Fuzzy systems}, 
  doi={10.1109/FUZZY.1992.258721}
}

@article{4809024, 
  author={M. k. {Alsmadi} and K. B. {Omar} and S. A. {Noah} and I. {Almarashdah}}, 
  journal={2009 IEEE International Advance Computing Conference}, 
  title={Performance Comparison of Multi-layer Perceptron (Back Propagation, Delta Rule and Perceptron) algorithms in Neural Networks}, 
  year={2009}, month={3}, pages={296-299}, 
  abstract={A multilayer perceptron is a feedforward artificial neural network model that maps sets of input data onto a set of appropriate output. It is a modification of the standard linear perceptron in that it uses three or more layers of neurons (nodes) with nonlinear activation functions, and is more powerful than the perceptron in that it can distinguish data that is not linearly separable, or separable by a hyper plane. MLP networks are general-purpose, flexible, nonlinear models consisting of a number of units organised into multiple layers. The complexity of the MLP network can be changed by varying the number of layers and the number of units in each layer. Given enough hidden units and enough data, it has been shown that MLPs can approximate virtually any function to any desired accuracy. This paper presents the performance comparison between Multi-layer Perceptron (back propagation, delta rule and perceptron). Perceptron is a steepest descent type algorithm that normally has slow convergence rate and the search for the global minimum often becomes trapped at poor local minima. The current study investigates the performance of three algorithms to train MLP networks. Its was found that the Perceptron algorithm are much better than others algorithms.}, keywords={backpropagation;convergence of numerical methods;multilayer perceptrons;recurrent neural nets;performance comparison;multilayer perceptron;back propagation;delta rule;feedforward artificial neural network;nonlinear activation function;steepest descent type algorithm;convergence rate;Multilayer perceptrons;Neural networks;Multi-layer neural network;Artificial neural networks;Neurons;Nervous system;Computer networks;Information science;Computer industry;Power system modeling;Back propagation;perceptron;delta rule learning;classification}, 
  doi={10.1109/IADCC.2009.4809024}
}

@article{article,
author = {Maier, Holger and Dandy, Graeme},
year = {2000},
month = {01},
pages = {101-124},
title = {Neural networks for the prediction and forecasting of water resources variables: A review of modelling issues and applications},
volume = {15},
journal = {Environmental Modelling and Software},
doi = {10.1016/S1364-8152(99)00007-9}
}

@book{guidorizzi2,
  title={Um curso de c{\'a}lculo},
  author={Guidorizzi, Hamilton Luiz},
  number={v. 2},
  isbn={8521604254},
  year={1986},
  publisher={LTC}
}


% https://adl1995.github.io/an-overview-of-activation-functions-used-in-neural-networks.html